{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print \"Hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print \"Hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn \n",
    "import neurolab as nl\n",
    "import numpy as np\n",
    "import scipy \n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('OnlineNewsPopularity.csv')\n",
    "df_train[\"Popularity\"]=0\n",
    "\n",
    "# # print type(np.int64(5))\n",
    "# for item in range(len(df_train[\" shares\"])):\n",
    "#     if df_train[\" shares\"][item] < (np.int64(1400)):\n",
    "#         df_train['Popularity'][item] =0\n",
    "#     else:\n",
    "#         df_train['Popularity'][item]=1\n",
    "        \n",
    "# print df_train['Popularity']\n",
    "        \n",
    "\n",
    "# df  = df_train\n",
    "# df[\"Sex\"] = df[\"Sex\"].replace(['male', 'female'], [0, 1])  \n",
    "# df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())\n",
    "# df[\"Embarked\"]=df[\"Embarked\"].replace(['S','Q','C'], [-1,0,1])\n",
    "# df[\"Embarked\"] = df[\"Embarked\"].fillna(df[\"Embarked\"].max())\n",
    "# df_train_70 = df[[\"Pclass\",\"Sex\",\"Age\"]]\n",
    "# df_train_70[\"Combined\"]= df[\"SibSp\"] + df[\"Parch\"]\n",
    "\n",
    "# df_out_70 = df[\"Survived\"]\n",
    "\n",
    "# df_test = pd.read_csv('test_lab6.csv')\n",
    "# df_out = df_test\n",
    "# df_out[\"Sex\"] = df_out[\"Sex\"].replace(['male', 'female'], [0, 1])  \n",
    "# df_out[\"Age\"] = df_out[\"Age\"].fillna(df_out[\"Age\"].mean())\n",
    "# df_out[\"Embarked\"]=df_out[\"Embarked\"].replace(['S','Q','C'], [-1,0,1])\n",
    "# df_out[\"Embarked\"] = df_out[\"Embarked\"].fillna(df_out[\"Embarked\"].max())\n",
    "# df_test_30 = df_out[[\"Pclass\",\"Sex\",\"Age\"]]\n",
    "# df_test_30[\"Combined\"]= df_out[\"SibSp\"] + df_out[\"Parch\"]\n",
    "\n",
    "\n",
    "# df_out_70 = df[\"Survived\"] \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print \"Hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Python/2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "for item in df_train[\" shares\"]:\n",
    "    if item < (np.int64(1400)):\n",
    "        df_train['Popularity'][a]=0\n",
    "    else:\n",
    "        df_train['Popularity'][a]=1\n",
    "    a+=1\n",
    "#     else:\n",
    "#         df_train['Popularity'][a]=1\n",
    "#     a+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tr = df_train[:30000]\n",
    "del df_tr[\"url\"]\n",
    "df_tr_output = df_train[\"Popularity\"][:30000]\n",
    "df_te = df_train[30000:]\n",
    "del df_te[\"url\"]\n",
    "df_te_output = df_train[\"Popularity\"][30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print \"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(df_tr.values,df_tr_output.values)\n",
    "shirish_pred = logreg.predict(df_te.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ..., 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print shirish_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9644\n",
      "9644\n"
     ]
    }
   ],
   "source": [
    "print len(df_te_output)\n",
    "print len(shirish_pred)\n",
    "b=0\n",
    "total=0\n",
    "for item in df_te_output:\n",
    "    if int(item) == int(shirish_pred[b]):\n",
    "        total+=1\n",
    "    b+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.862401493156\n"
     ]
    }
   ],
   "source": [
    "accuracy = total * 1.0/(len(shirish_pred))\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8fbe7931c1b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtotal_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshirish_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mshirish_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf_te_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m          \u001b[0mtotal_\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maccuracy_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshirish_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 1911\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   1912\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_value (pandas/index.c:3234)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_value (pandas/index.c:2931)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3891)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.Int64HashTable.get_item (pandas/hashtable.c:6527)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.Int64HashTable.get_item (pandas/hashtable.c:6465)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "total_ = 0 \n",
    "for each in range(len(shirish_pred)):\n",
    "    if shirish_pred[each] == df_te_output[each]:\n",
    "         total_+= 1\n",
    "accuracy_ = total_ * 1.0/(len(shirish_pred))\n",
    "print accuracy_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 0.83630312339989776)\n"
     ]
    }
   ],
   "source": [
    "# Fetching the training and test set and assigning the age column float datatype\n",
    "train = pd.read_csv('train_lab6.csv', dtype={\"Age\": np.float64}, )\n",
    "test  = pd.read_csv('test_lab6.csv', dtype={\"Age\": np.float64}, )\n",
    "# Cleaning the dataset\n",
    "def harmonize_data(titanic):\n",
    "    \n",
    "    # Filling the blank data\n",
    "    titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].mean())\n",
    "    titanic[\"Fare\"] = titanic[\"Fare\"].fillna(titanic[\"Fare\"].mean())\n",
    "    titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(\"S\")\n",
    "    \n",
    "    # Assigning binary form to data for calculation purpose\n",
    "    titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 1\n",
    "    titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 0\n",
    "    titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "    titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "    titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "\n",
    "    return titanic\n",
    "\n",
    "\n",
    "#Defining the clean dataset    \n",
    "train_data = harmonize_data(train)\n",
    "test_data  = harmonize_data(test)\n",
    "\n",
    "# Feature engineering\n",
    "train_data[\"SP\"] = (train_data[\"SibSp\"]*train_data[\"Parch\"])**2\n",
    "train_data[\"PA\"] = train_data[\"Pclass\"]*train_data[\"Age\"]\n",
    "\n",
    "test_data[\"SP\"] = (test_data[\"SibSp\"]*test_data[\"Parch\"])**2\n",
    "test_data[\"PA\"] = test_data[\"Pclass\"]*test_data[\"Age\"]\n",
    "\n",
    "# Defining predictor\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"PA\", \"SP\"]\n",
    "\n",
    "#Applying method\n",
    "max_score = 0\n",
    "best_n = 0\n",
    "for n in range(1,100):\n",
    "    rfc_scr = 0.\n",
    "    rfc = RandomForestClassifier(n_estimators=n)\n",
    "    for train, test in KFold(len(train_data), n_folds=10, shuffle=True):\n",
    "        rfc.fit(train_data[predictors].T[train].T, train_data[\"Survived\"].T[train].T)\n",
    "        rfc_scr += rfc.score(train_data[predictors].T[test].T, train_data[\"Survived\"].T[test].T)/10\n",
    "    if rfc_scr > max_score:\n",
    "        max_score = rfc_scr\n",
    "        best_n = n\n",
    "\n",
    "print(best_n, max_score)\n",
    "rfc = RandomForestClassifier(best_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 1\n",
      " 1 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1 0 1 0\n",
      " 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1\n",
      " 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 1 0 1 1 0 0 0\n",
      " 1 0 1 1 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(train_data[predictors], train_data[\"Survived\"])\n",
    "lynell_pred = rfc.predict(test_data[predictors])\n",
    "\n",
    "print lynell_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 0 0\n",
      " 1 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 1 1 1 1 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/pandas/core/generic.py:2387: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "#Read the train data into a dataframe\n",
    "df = pd.read_csv(\"train_lab6.csv\", sep = ',')\n",
    "df_train = df[['Pclass', 'Sex', 'Age', 'Parch', 'Embarked']]\n",
    "df_train_class = df[['Survived']]\n",
    "\n",
    "def pre_process(data_frame):\n",
    "    #fill NaN embarked with most frequently embarked stations\n",
    "    most_frequent_embarked = data_frame['Embarked'].max()\n",
    "    data_frame.Embarked = data_frame.Embarked.fillna(most_frequent_embarked)\n",
    "\n",
    "    #Fill NaN age with average\n",
    "    avg_age = data_frame.Age.mean()\n",
    "    data_frame.Age = data_frame.Age.fillna(avg_age)\n",
    "    \n",
    "pre_process(df_train)\n",
    "\n",
    "#vectorize the labels\n",
    "df_train_v = df_train.to_dict('records')\n",
    "vec = DictVectorizer()\n",
    "df_train_v = vec.fit_transform(df_train_v).toarray()\n",
    "\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(df_train_v, df_train_class.values)\n",
    "dt = DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "dt.fit(data_train, target_train)\n",
    "\n",
    "df_test = pd.read_csv(\"test_lab6.csv\", sep = ',')\n",
    "df_test6 = df_test[['Pclass', 'Sex', 'Age', 'Parch', 'Embarked']]\n",
    "pre_process(df_test6)\n",
    "df_test6_v = df_test6.to_dict('records')\n",
    "df_test6_v = vec.transform(df_test6_v).toarray()\n",
    "\n",
    "bhuvana_pred = dt.predict(df_test6_v)\n",
    "\n",
    "print bhuvana_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "final_pred = []\n",
    "for i in range(len(shirish_pred)):\n",
    "    count = shirish_pred[i] + lynell_pred[i] + bhuvana_pred[i]\n",
    "    \n",
    "    if count <= 1:\n",
    "        final_pred.append(0)\n",
    "    else:\n",
    "        final_pred.append(1)\n",
    "\n",
    "print final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def writeToFile(pred_data, ids):\n",
    "    with open(\"predicted.csv\", \"w\") as of:\n",
    "        of.write(\"PassengerId,Survived\\n\" )\n",
    "        for i in range(len(pred_data)):\n",
    "            of.write(str(ids[i][0]) + \",\" + str(pred_data[i]) + \"\\n\")\n",
    "            \n",
    "test_ids = df_test[['PassengerId']].values\n",
    "writeToFile(final_pred, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
